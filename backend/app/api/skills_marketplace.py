"""Skills marketplace and skill pack APIs."""

from __future__ import annotations

import ipaddress
import json
import re
import subprocess
from dataclasses import dataclass
from pathlib import Path
from tempfile import TemporaryDirectory
from typing import TYPE_CHECKING, Iterator, TextIO
from urllib.parse import unquote, urlparse
from uuid import UUID

from fastapi import APIRouter, Depends, HTTPException, Query, Response, status
from sqlalchemy import func, or_
from sqlmodel import col, select

from app.api.deps import require_org_admin
from app.core.time import utcnow
from app.db.session import get_session
from app.models.gateways import Gateway
from app.models.skills import GatewayInstalledSkill, MarketplaceSkill, SkillPack
from app.schemas.common import OkResponse
from app.schemas.skills_marketplace import (
    MarketplaceSkillActionResponse,
    MarketplaceSkillCardRead,
    MarketplaceSkillCreate,
    MarketplaceSkillRead,
    SkillPackCreate,
    SkillPackRead,
    SkillPackSyncResponse,
)
from app.services.openclaw.gateway_dispatch import GatewayDispatchService
from app.services.openclaw.gateway_resolver import (
    gateway_client_config,
    require_gateway_workspace_root,
)
from app.services.openclaw.gateway_rpc import OpenClawGatewayError
from app.services.openclaw.shared import GatewayAgentIdentity
from app.services.organizations import OrganizationContext

if TYPE_CHECKING:
    from sqlmodel.ext.asyncio.session import AsyncSession

router = APIRouter(prefix="/skills", tags=["skills"])
SESSION_DEP = Depends(get_session)
ORG_ADMIN_DEP = Depends(require_org_admin)
GATEWAY_ID_QUERY = Query(...)

ALLOWED_PACK_SOURCE_SCHEMES = {"https"}
GIT_CLONE_TIMEOUT_SECONDS = 30
GIT_REV_PARSE_TIMEOUT_SECONDS = 10
BRANCH_NAME_ALLOWED_RE = r"^[A-Za-z0-9._/\-]+$"
SKILLS_INDEX_READ_CHUNK_BYTES = 16 * 1024


def _normalize_pack_branch(raw_branch: str | None) -> str:
    if not raw_branch:
        return "main"
    normalized = raw_branch.strip()
    if not normalized:
        return "main"
    if any(ch in normalized for ch in {"\n", "\r", "\t"}):
        return "main"
    if not re.match(BRANCH_NAME_ALLOWED_RE, normalized):
        return "main"
    return normalized


@dataclass(frozen=True)
class PackSkillCandidate:
    """Single skill discovered in a pack repository."""

    name: str
    description: str | None
    source_url: str
    category: str | None = None
    risk: str | None = None
    source: str | None = None
    metadata: dict[str, object] | None = None


def _skills_install_dir(workspace_root: str) -> str:
    normalized = workspace_root.rstrip("/\\")
    if not normalized:
        return "skills"
    return f"{normalized}/skills"


def _infer_skill_name(source_url: str) -> str:
    parsed = urlparse(source_url)
    path = parsed.path.rstrip("/")
    candidate = path.rsplit("/", maxsplit=1)[-1] if path else parsed.netloc
    candidate = unquote(candidate).removesuffix(".git").replace("-", " ").replace("_", " ")
    if candidate.strip():
        return candidate.strip()
    return "Skill"


def _infer_skill_description(skill_file: Path) -> str | None:
    try:
        content = skill_file.read_text(encoding="utf-8", errors="ignore")
    except OSError:
        return None

    lines = [line.strip() for line in content.splitlines()]
    if not lines:
        return None

    in_frontmatter = False
    for line in lines:
        if line == "---":
            in_frontmatter = not in_frontmatter
            continue
        if in_frontmatter:
            if line.lower().startswith("description:"):
                value = line.split(":", maxsplit=1)[-1].strip().strip("\"'")
                return value or None
            continue
        if not line or line.startswith("#"):
            continue
        return line

    return None


def _infer_skill_display_name(skill_file: Path, fallback: str) -> str:
    try:
        content = skill_file.read_text(encoding="utf-8", errors="ignore")
    except OSError:
        content = ""

    in_frontmatter = False
    for raw_line in content.splitlines():
        line = raw_line.strip()
        if line == "---":
            in_frontmatter = not in_frontmatter
            continue
        if in_frontmatter and line.lower().startswith("name:"):
            value = line.split(":", maxsplit=1)[-1].strip().strip("\"'")
            if value:
                return value

    for raw_line in content.splitlines():
        line = raw_line.strip()
        if line.startswith("#"):
            heading = line.lstrip("#").strip()
            if heading:
                return heading

    normalized_fallback = fallback.replace("-", " ").replace("_", " ").strip()
    return normalized_fallback or "Skill"


def _normalize_repo_source_url(source_url: str) -> str:
    normalized = source_url.strip().rstrip("/")
    if normalized.endswith(".git"):
        return normalized[: -len(".git")]
    return normalized


def _normalize_pack_source_url(source_url: str) -> str:
    """Normalize pack repository source URLs for uniqueness checks."""
    return _normalize_repo_source_url(source_url)


def _validate_pack_source_url(source_url: str) -> None:
    """Validate that a skill pack source URL is safe to clone.

    The current implementation is intentionally conservative:
    - allow only https URLs
    - block localhost
    - block literal private/loopback/link-local IPs

    Note: DNS-based private resolution is not checked here.
    """

    parsed = urlparse(source_url)
    scheme = (parsed.scheme or "").lower()
    if scheme not in ALLOWED_PACK_SOURCE_SCHEMES:
        raise ValueError(f"Unsupported pack source URL scheme: {parsed.scheme!r}")

    host = (parsed.hostname or "").strip().lower()
    if not host:
        raise ValueError("Pack source URL must include a hostname")

    if host in {"localhost"}:
        raise ValueError("Pack source URL hostname is not allowed")

    if host != "github.com":
        raise ValueError(
            "Pack source URL must be a GitHub repository URL (https://github.com/<owner>/<repo>)"
        )

    path = parsed.path.strip("/")
    if not path or path.count("/") < 1:
        raise ValueError(
            "Pack source URL must be a GitHub repository URL (https://github.com/<owner>/<repo>)"
        )

    try:
        ip = ipaddress.ip_address(host)
    except ValueError:
        return

    if ip.is_private or ip.is_loopback or ip.is_link_local or ip.is_reserved or ip.is_multicast:
        raise ValueError("Pack source URL hostname is not allowed")


def _to_tree_source_url(repo_source_url: str, branch: str, rel_path: str) -> str:
    repo_url = _normalize_repo_source_url(repo_source_url)
    safe_branch = branch.strip() or "main"
    rel = rel_path.strip().lstrip("/")
    if not rel:
        return f"{repo_url}/tree/{safe_branch}"
    return f"{repo_url}/tree/{safe_branch}/{rel}"


def _repo_base_from_tree_source_url(source_url: str) -> str | None:
    parsed = urlparse(source_url)
    marker = "/tree/"
    marker_index = parsed.path.find(marker)
    if marker_index <= 0:
        return None

    repo_path = parsed.path[:marker_index]
    if not repo_path:
        return None
    return _normalize_repo_source_url(f"{parsed.scheme}://{parsed.netloc}{repo_path}")


def _build_skill_count_by_repo(skills: list[MarketplaceSkill]) -> dict[str, int]:
    counts: dict[str, int] = {}
    for skill in skills:
        repo_base = _repo_base_from_tree_source_url(skill.source_url)
        if repo_base is None:
            continue
        counts[repo_base] = counts.get(repo_base, 0) + 1
    return counts


def _normalize_repo_path(path_value: str) -> str:
    cleaned = path_value.strip().replace("\\", "/")
    while cleaned.startswith("./"):
        cleaned = cleaned[2:]
    cleaned = cleaned.lstrip("/").rstrip("/")

    lowered = cleaned.lower()
    if lowered.endswith("/skill.md"):
        cleaned = cleaned.rsplit("/", maxsplit=1)[0]
    elif lowered == "skill.md":
        cleaned = ""

    return cleaned


def _coerce_index_entries(payload: object) -> list[dict[str, object]]:
    if isinstance(payload, list):
        return [entry for entry in payload if isinstance(entry, dict)]

    if isinstance(payload, dict):
        entries = payload.get("skills")
        if isinstance(entries, list):
            return [entry for entry in entries if isinstance(entry, dict)]

    return []


class _StreamingJSONReader:
    """Incrementally decode JSON content from a file object."""

    def __init__(self, file_obj: TextIO):
        self._file_obj = file_obj
        self._buffer = ""
        self._position = 0
        self._eof = False
        self._decoder = json.JSONDecoder()

    def _fill_buffer(self) -> None:
        if self._eof:
            return

        chunk = self._file_obj.read(SKILLS_INDEX_READ_CHUNK_BYTES)
        if not chunk:
            self._eof = True
            return
        self._buffer += chunk

    def _peek(self) -> str | None:
        self._skip_whitespace()
        if self._position >= len(self._buffer):
            return None
        return self._buffer[self._position]

    def _skip_whitespace(self) -> None:
        while True:
            while self._position < len(self._buffer) and self._buffer[self._position].isspace():
                self._position += 1

            if self._position < len(self._buffer):
                return

            self._fill_buffer()
            if self._position < len(self._buffer):
                return
            if self._eof:
                return

    def _decode_value(self) -> object:
        self._skip_whitespace()

        while True:
            try:
                value, end = self._decoder.raw_decode(self._buffer, self._position)
                self._position = end
                return value
            except json.JSONDecodeError:
                if self._eof:
                    raise RuntimeError("skills_index.json is not valid JSON")
                self._fill_buffer()
                self._skip_whitespace()
                if self._position >= len(self._buffer):
                    if self._eof:
                        raise RuntimeError("skills_index.json is not valid JSON")

    def _consume_char(self, expected: str) -> None:
        self._skip_whitespace()
        if self._position >= len(self._buffer):
            self._fill_buffer()
            self._skip_whitespace()
        if self._position >= len(self._buffer):
            raise RuntimeError("skills_index.json is not valid JSON")

        actual = self._buffer[self._position]
        if actual != expected:
            raise RuntimeError("skills_index.json is not valid JSON")
        self._position += 1

    def read_top_level_entries(self) -> list[dict[str, object]]:
        self._fill_buffer()
        self._skip_whitespace()
        first = self._peek()
        if first is None:
            raise RuntimeError("skills_index.json is not valid JSON")

        if first == "[":
            self._position += 1
            return list(self._read_array_values())
        if first == "{":
            self._position += 1
            return list(self._read_skills_from_object())
        raise RuntimeError("skills_index.json is not valid JSON")

    def _read_array_values(self) -> Iterator[dict[str, object]]:
        while True:
            self._skip_whitespace()
            current = self._peek()
            if current is None:
                if self._eof:
                    raise RuntimeError("skills_index.json is not valid JSON")
                continue
            if current == "]":
                self._position += 1
                return

            if current == ",":
                self._position += 1
                continue

            entry = self._decode_value()
            if isinstance(entry, dict):
                yield entry
            else:
                raise RuntimeError("skills_index.json is not valid JSON")

    def _read_skills_from_object(self) -> Iterator[dict[str, object]]:
        while True:
            self._skip_whitespace()
            current = self._peek()
            if current is None:
                if self._eof:
                    raise RuntimeError("skills_index.json is not valid JSON")
                continue

            if current == "}":
                self._position += 1
                return

            key = self._decode_value()
            if not isinstance(key, str):
                raise RuntimeError("skills_index.json is not valid JSON")

            self._skip_whitespace()
            if self._peek() == ":":
                self._position += 1
            else:
                self._consume_char(":")

            if key == "skills":
                self._skip_whitespace()
                current = self._peek()
                if current is None:
                    if self._eof:
                        raise RuntimeError("skills_index.json is not valid JSON")
                    continue

                if current != "[":
                    value = self._decode_value()
                    if isinstance(value, list):
                        for entry in value:
                            if isinstance(entry, dict):
                                yield entry
                            else:
                                raise RuntimeError("skills_index.json is not valid JSON")
                    continue

                self._position += 1
                yield from self._read_array_values()
            else:
                self._decode_value()

            self._skip_whitespace()
            current = self._peek()
            if current == ",":
                self._position += 1
                continue
            if current == "}":
                self._position += 1
                return


def _collect_pack_skills_from_index(
    *,
    repo_dir: Path,
    source_url: str,
    branch: str,
    discovery_warnings: list[str] | None = None,
) -> list[PackSkillCandidate] | None:
    index_file = repo_dir / "skills_index.json"
    if not index_file.is_file():
        return None

    try:
        with index_file.open(encoding="utf-8") as fp:
            payload = _StreamingJSONReader(fp).read_top_level_entries()
    except OSError as exc:
        raise RuntimeError("unable to read skills_index.json") from exc
    except RuntimeError as exc:
        if discovery_warnings is not None:
            discovery_warnings.append(f"Failed to parse skills_index.json: {exc}")
        return None

    found: dict[str, PackSkillCandidate] = {}
    for entry in _coerce_index_entries(payload):
        indexed_path = entry.get("path")
        has_indexed_path = False
        rel_path = ""
        resolved_skill_path: str | None = None
        if isinstance(indexed_path, str) and indexed_path.strip():
            has_indexed_path = True
            rel_path = _normalize_repo_path(indexed_path)
            resolved_skill_path = rel_path or None

        indexed_source = entry.get("source_url")
        candidate_source_url: str | None = None
        resolved_metadata: dict[str, object] = {
            "discovery_mode": "skills_index",
            "pack_branch": branch,
        }
        if isinstance(indexed_source, str) and indexed_source.strip():
            source_candidate = indexed_source.strip()
            resolved_metadata["source_url"] = source_candidate
            if source_candidate.startswith(("https://", "http://")):
                parsed = urlparse(source_candidate)
                if parsed.path:
                    marker = "/tree/"
                    marker_index = parsed.path.find(marker)
                    if marker_index > 0:
                        tree_suffix = parsed.path[marker_index + len(marker) :]
                        slash_index = tree_suffix.find("/")
                        candidate_path = tree_suffix[slash_index + 1 :] if slash_index >= 0 else ""
                        resolved_skill_path = _normalize_repo_path(candidate_path)
                candidate_source_url = source_candidate
            else:
                indexed_rel = _normalize_repo_path(source_candidate)
                resolved_skill_path = resolved_skill_path or indexed_rel
                resolved_metadata["resolved_path"] = indexed_rel
                if indexed_rel:
                    candidate_source_url = _to_tree_source_url(source_url, branch, indexed_rel)
        elif has_indexed_path:
            resolved_metadata["resolved_path"] = rel_path
            candidate_source_url = _to_tree_source_url(source_url, branch, rel_path)
            if rel_path:
                resolved_skill_path = rel_path

        if not candidate_source_url:
            continue

        indexed_name = entry.get("name")
        if isinstance(indexed_name, str) and indexed_name.strip():
            name = indexed_name.strip()
        else:
            fallback = Path(rel_path).name if rel_path else "Skill"
            name = _infer_skill_name(fallback)

        indexed_description = entry.get("description")
        description = (
            indexed_description.strip()
            if isinstance(indexed_description, str) and indexed_description.strip()
            else None
        )
        indexed_category = entry.get("category")
        category = (
            indexed_category.strip()
            if isinstance(indexed_category, str) and indexed_category.strip()
            else None
        )
        indexed_risk = entry.get("risk")
        risk = (
            indexed_risk.strip() if isinstance(indexed_risk, str) and indexed_risk.strip() else None
        )
        source_label = resolved_skill_path

        found[candidate_source_url] = PackSkillCandidate(
            name=name,
            description=description,
            source_url=candidate_source_url,
            category=category,
            risk=risk,
            source=source_label,
            metadata=resolved_metadata,
        )

    return list(found.values())


def _collect_pack_skills_from_repo(
    *,
    repo_dir: Path,
    source_url: str,
    branch: str,
    discovery_warnings: list[str] | None = None,
) -> list[PackSkillCandidate]:
    indexed = _collect_pack_skills_from_index(
        repo_dir=repo_dir,
        source_url=source_url,
        branch=branch,
        discovery_warnings=discovery_warnings,
    )
    if indexed is not None:
        return indexed

    found: dict[str, PackSkillCandidate] = {}
    for skill_file in sorted(repo_dir.rglob("SKILL.md")):
        rel_file_parts = skill_file.relative_to(repo_dir).parts
        # Skip hidden folders like .git, .github, etc.
        if any(part.startswith(".") for part in rel_file_parts):
            continue

        skill_dir = skill_file.parent
        rel_dir = "" if skill_dir == repo_dir else skill_dir.relative_to(repo_dir).as_posix()
        fallback_name = _infer_skill_name(source_url) if skill_dir == repo_dir else skill_dir.name
        name = _infer_skill_display_name(skill_file, fallback=fallback_name)
        description = _infer_skill_description(skill_file)
        tree_url = _to_tree_source_url(source_url, branch, rel_dir)
        found[tree_url] = PackSkillCandidate(
            name=name,
            description=description,
            source_url=tree_url,
            metadata={
                "discovery_mode": "skills_md",
                "pack_branch": branch,
                "skill_dir": rel_dir,
            },
        )

    if found:
        return list(found.values())

    return []


def _collect_pack_skills(
    *,
    source_url: str,
    branch: str = "main",
) -> list[PackSkillCandidate]:
    """Clone a pack repository and collect skills from index or `skills/**/SKILL.md`."""
    return _collect_pack_skills_with_warnings(
        source_url=source_url,
        branch=branch,
    )[0]


def _collect_pack_skills_with_warnings(
    *,
    source_url: str,
    branch: str,
) -> tuple[list[PackSkillCandidate], list[str]]:
    """Clone a pack repository and return discovered skills plus sync warnings."""
    # Defense-in-depth: validate again at point of use before invoking git.
    _validate_pack_source_url(source_url)

    requested_branch = _normalize_pack_branch(branch)
    discovery_warnings: list[str] = []

    with TemporaryDirectory(prefix="skill-pack-sync-") as tmp_dir:
        repo_dir = Path(tmp_dir)
        used_branch = requested_branch
        try:
            subprocess.run(
                [
                    "git",
                    "clone",
                    "--depth",
                    "1",
                    "--single-branch",
                    "--branch",
                    requested_branch,
                    source_url,
                    str(repo_dir),
                ],
                check=True,
                capture_output=True,
                text=True,
                timeout=GIT_CLONE_TIMEOUT_SECONDS,
            )
        except FileNotFoundError as exc:
            raise RuntimeError("git binary not available on the server") from exc
        except subprocess.TimeoutExpired as exc:
            raise RuntimeError("timed out cloning pack repository") from exc
        except subprocess.CalledProcessError as exc:
            if requested_branch != "main":
                try:
                    subprocess.run(
                        ["git", "clone", "--depth", "1", source_url, str(repo_dir)],
                        check=True,
                        capture_output=True,
                        text=True,
                        timeout=GIT_CLONE_TIMEOUT_SECONDS,
                    )
                    used_branch = "main"
                except (
                    FileNotFoundError,
                    subprocess.TimeoutExpired,
                    subprocess.CalledProcessError,
                ):
                    stderr = (exc.stderr or "").strip()
                    detail = "unable to clone pack repository"
                    if stderr:
                        detail = f"{detail}: {stderr.splitlines()[0][:200]}"
                    raise RuntimeError(detail) from exc
            else:
                stderr = (exc.stderr or "").strip()
                detail = "unable to clone pack repository"
                if stderr:
                    detail = f"{detail}: {stderr.splitlines()[0][:200]}"
                raise RuntimeError(detail) from exc

        try:
            discovered_branch = subprocess.run(
                ["git", "-C", str(repo_dir), "rev-parse", "--abbrev-ref", "HEAD"],
                check=True,
                capture_output=True,
                text=True,
                timeout=GIT_REV_PARSE_TIMEOUT_SECONDS,
            ).stdout.strip()
        except (FileNotFoundError, subprocess.TimeoutExpired, subprocess.CalledProcessError):
            discovered_branch = used_branch or "main"

        return (
            _collect_pack_skills_from_repo(
                repo_dir=repo_dir,
                source_url=source_url,
                branch=_normalize_pack_branch(discovered_branch),
                discovery_warnings=discovery_warnings,
            ),
            discovery_warnings,
        )


def _install_instruction(*, skill: MarketplaceSkill, gateway: Gateway) -> str:
    install_dir = _skills_install_dir(gateway.workspace_root)
    return (
        "MISSION CONTROL SKILL INSTALL REQUEST\n"
        f"Skill name: {skill.name}\n"
        f"Skill source URL: {skill.source_url}\n"
        f"Install destination: {install_dir}\n\n"
        "Actions:\n"
        "1. Ensure the install destination exists.\n"
        "2. Install or update the skill from the source URL into the destination.\n"
        "3. Verify the skill is discoverable by the runtime.\n"
        "4. Reply with success or failure details."
    )


def _uninstall_instruction(*, skill: MarketplaceSkill, gateway: Gateway) -> str:
    install_dir = _skills_install_dir(gateway.workspace_root)
    return (
        "MISSION CONTROL SKILL UNINSTALL REQUEST\n"
        f"Skill name: {skill.name}\n"
        f"Skill source URL: {skill.source_url}\n"
        f"Install destination: {install_dir}\n\n"
        "Actions:\n"
        "1. Remove the skill assets previously installed from this source URL.\n"
        "2. Ensure the skill is no longer discoverable by the runtime.\n"
        "3. Reply with success or failure details."
    )


def _as_card(
    *,
    skill: MarketplaceSkill,
    installation: GatewayInstalledSkill | None,
) -> MarketplaceSkillCardRead:
    card_source: str | None = skill.source_url
    if not card_source:
        card_source = skill.source

    return MarketplaceSkillCardRead(
        id=skill.id,
        organization_id=skill.organization_id,
        name=skill.name,
        description=skill.description,
        category=skill.category,
        risk=skill.risk,
        source=card_source,
        source_url=skill.source_url,
        metadata_=skill.metadata_ or {},
        created_at=skill.created_at,
        updated_at=skill.updated_at,
        installed=installation is not None,
        installed_at=installation.created_at if installation is not None else None,
    )


def _as_skill_pack_read(pack: SkillPack) -> SkillPackRead:
    return SkillPackRead(
        id=pack.id,
        organization_id=pack.organization_id,
        name=pack.name,
        description=pack.description,
        source_url=pack.source_url,
        branch=pack.branch or "main",
        metadata_=pack.metadata_ or {},
        skill_count=0,
        created_at=pack.created_at,
        updated_at=pack.updated_at,
    )


def _pack_skill_count(*, pack: SkillPack, count_by_repo: dict[str, int]) -> int:
    repo_base = _normalize_repo_source_url(pack.source_url)
    return count_by_repo.get(repo_base, 0)


async def _require_gateway_for_org(
    *,
    gateway_id: UUID,
    session: AsyncSession,
    ctx: OrganizationContext,
) -> Gateway:
    gateway = await Gateway.objects.by_id(gateway_id).first(session)
    if gateway is None or gateway.organization_id != ctx.organization.id:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Gateway not found",
        )
    return gateway


async def _require_marketplace_skill_for_org(
    *,
    skill_id: UUID,
    session: AsyncSession,
    ctx: OrganizationContext,
) -> MarketplaceSkill:
    skill = await MarketplaceSkill.objects.by_id(skill_id).first(session)
    if skill is None or skill.organization_id != ctx.organization.id:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Marketplace skill not found",
        )
    return skill


async def _require_skill_pack_for_org(
    *,
    pack_id: UUID,
    session: AsyncSession,
    ctx: OrganizationContext,
) -> SkillPack:
    pack = await SkillPack.objects.by_id(pack_id).first(session)
    if pack is None or pack.organization_id != ctx.organization.id:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Skill pack not found",
        )
    return pack


async def _dispatch_gateway_instruction(
    *,
    session: AsyncSession,
    gateway: Gateway,
    message: str,
) -> None:
    dispatch = GatewayDispatchService(session)
    config = gateway_client_config(gateway)
    session_key = GatewayAgentIdentity.session_key(gateway)
    await dispatch.send_agent_message(
        session_key=session_key,
        config=config,
        agent_name="Gateway Agent",
        message=message,
        deliver=True,
    )


async def _load_pack_skill_count_by_repo(
    *,
    session: AsyncSession,
    organization_id: UUID,
) -> dict[str, int]:
    skills = await MarketplaceSkill.objects.filter_by(organization_id=organization_id).all(session)
    return _build_skill_count_by_repo(skills)


def _as_skill_pack_read_with_count(
    *,
    pack: SkillPack,
    count_by_repo: dict[str, int],
) -> SkillPackRead:
    return _as_skill_pack_read(pack).model_copy(
        update={"skill_count": _pack_skill_count(pack=pack, count_by_repo=count_by_repo)},
    )


async def _sync_gateway_installation_state(
    *,
    session: AsyncSession,
    gateway_id: UUID,
    skill_id: UUID,
    installed: bool,
) -> None:
    installation = await GatewayInstalledSkill.objects.filter_by(
        gateway_id=gateway_id,
        skill_id=skill_id,
    ).first(session)
    if installed:
        if installation is None:
            session.add(
                GatewayInstalledSkill(
                    gateway_id=gateway_id,
                    skill_id=skill_id,
                ),
            )
            return

        installation.updated_at = utcnow()
        session.add(installation)
        return

    if installation is not None:
        await session.delete(installation)


async def _run_marketplace_skill_action(
    *,
    session: AsyncSession,
    ctx: OrganizationContext,
    skill_id: UUID,
    gateway_id: UUID,
    installed: bool,
) -> MarketplaceSkillActionResponse:
    gateway = await _require_gateway_for_org(gateway_id=gateway_id, session=session, ctx=ctx)
    require_gateway_workspace_root(gateway)
    skill = await _require_marketplace_skill_for_org(skill_id=skill_id, session=session, ctx=ctx)
    instruction = (
        _install_instruction(skill=skill, gateway=gateway)
        if installed
        else _uninstall_instruction(skill=skill, gateway=gateway)
    )
    try:
        await _dispatch_gateway_instruction(
            session=session,
            gateway=gateway,
            message=instruction,
        )
    except OpenClawGatewayError as exc:
        raise HTTPException(
            status_code=status.HTTP_502_BAD_GATEWAY,
            detail=str(exc),
        ) from exc

    await _sync_gateway_installation_state(
        session=session,
        gateway_id=gateway.id,
        skill_id=skill.id,
        installed=installed,
    )
    await session.commit()
    return MarketplaceSkillActionResponse(
        skill_id=skill.id,
        gateway_id=gateway.id,
        installed=installed,
    )


def _apply_pack_candidate_updates(
    *,
    existing: MarketplaceSkill,
    candidate: PackSkillCandidate,
) -> bool:
    changed = False
    if existing.name != candidate.name:
        existing.name = candidate.name
        changed = True
    if existing.description != candidate.description:
        existing.description = candidate.description
        changed = True
    if existing.category != candidate.category:
        existing.category = candidate.category
        changed = True
    if existing.risk != candidate.risk:
        existing.risk = candidate.risk
        changed = True
    if existing.source != candidate.source:
        existing.source = candidate.source
        changed = True
    if existing.metadata_ != (candidate.metadata or {}):
        existing.metadata_ = candidate.metadata or {}
        changed = True
    return changed


@router.get("/marketplace", response_model=list[MarketplaceSkillCardRead])
async def list_marketplace_skills(
    response: Response,
    gateway_id: UUID = GATEWAY_ID_QUERY,
    search: str | None = Query(default=None),
    category: str | None = Query(default=None),
    risk: str | None = Query(default=None),
    pack_id: UUID | None = Query(default=None, alias="pack_id"),
    limit: int | None = Query(default=None, ge=1, le=200),
    offset: int = Query(default=0, ge=0),
    session: AsyncSession = SESSION_DEP,
    ctx: OrganizationContext = ORG_ADMIN_DEP,
) -> list[MarketplaceSkillCardRead]:
    """List marketplace cards for an org and annotate install state for a gateway."""
    gateway = await _require_gateway_for_org(gateway_id=gateway_id, session=session, ctx=ctx)
    skills_query = MarketplaceSkill.objects.filter_by(organization_id=ctx.organization.id)

    normalized_category = (category or "").strip().lower()
    if normalized_category:
        if normalized_category == "uncategorized":
            skills_query = skills_query.filter(
                or_(
                    col(MarketplaceSkill.category).is_(None),
                    func.trim(col(MarketplaceSkill.category)) == "",
                ),
            )
        else:
            skills_query = skills_query.filter(
                func.lower(func.trim(col(MarketplaceSkill.category))) == normalized_category,
            )

    normalized_risk = (risk or "").strip().lower()
    if normalized_risk:
        if normalized_risk == "uncategorized":
            skills_query = skills_query.filter(
                or_(
                    col(MarketplaceSkill.risk).is_(None),
                    func.trim(col(MarketplaceSkill.risk)) == "",
                ),
            )
        else:
            skills_query = skills_query.filter(
                func.lower(func.trim(func.coalesce(col(MarketplaceSkill.risk), "")))
                == normalized_risk,
            )

    if pack_id is not None:
        pack = await _require_skill_pack_for_org(pack_id=pack_id, session=session, ctx=ctx)
        normalized_pack_source = _normalize_pack_source_url(pack.source_url)
        skills_query = skills_query.filter(
            col(MarketplaceSkill.source_url).ilike(f"{normalized_pack_source}%"),
        )

    normalized_search = (search or "").strip()
    if normalized_search:
        search_like = f"%{normalized_search}%"
        skills_query = skills_query.filter(
            or_(
                col(MarketplaceSkill.name).ilike(search_like),
                col(MarketplaceSkill.description).ilike(search_like),
                col(MarketplaceSkill.category).ilike(search_like),
                col(MarketplaceSkill.risk).ilike(search_like),
                col(MarketplaceSkill.source).ilike(search_like),
            ),
        )

    if limit is not None:
        count_statement = select(func.count()).select_from(
            skills_query.statement.order_by(None).subquery()
        )
        total_count = int((await session.exec(count_statement)).one() or 0)
        response.headers["X-Total-Count"] = str(total_count)
        response.headers["X-Limit"] = str(limit)
        response.headers["X-Offset"] = str(offset)

    ordered_query = skills_query.order_by(col(MarketplaceSkill.created_at).desc())
    if limit is not None:
        ordered_query = ordered_query.offset(offset).limit(limit)
    skills = await ordered_query.all(session)
    installations = await GatewayInstalledSkill.objects.filter_by(gateway_id=gateway.id).all(
        session
    )
    installed_by_skill_id = {record.skill_id: record for record in installations}
    return [
        _as_card(skill=skill, installation=installed_by_skill_id.get(skill.id)) for skill in skills
    ]


@router.post("/marketplace", response_model=MarketplaceSkillRead)
async def create_marketplace_skill(
    payload: MarketplaceSkillCreate,
    session: AsyncSession = SESSION_DEP,
    ctx: OrganizationContext = ORG_ADMIN_DEP,
) -> MarketplaceSkill:
    """Register or update a direct marketplace skill URL in the catalog."""
    source_url = str(payload.source_url).strip()
    existing = await MarketplaceSkill.objects.filter_by(
        organization_id=ctx.organization.id,
        source_url=source_url,
    ).first(session)
    if existing is not None:
        changed = False
        if payload.name and existing.name != payload.name:
            existing.name = payload.name
            changed = True
        if payload.description is not None and existing.description != payload.description:
            existing.description = payload.description
            changed = True
        if changed:
            existing.updated_at = utcnow()
            session.add(existing)
            await session.commit()
            await session.refresh(existing)
        existing.metadata_ = existing.metadata_ or {}
        return existing

    skill = MarketplaceSkill(
        organization_id=ctx.organization.id,
        source_url=source_url,
        name=payload.name or _infer_skill_name(source_url),
        description=payload.description,
        metadata_={},
    )
    session.add(skill)
    await session.commit()
    await session.refresh(skill)
    skill.metadata_ = skill.metadata_ or {}
    return skill


@router.delete("/marketplace/{skill_id}", response_model=OkResponse)
async def delete_marketplace_skill(
    skill_id: UUID,
    session: AsyncSession = SESSION_DEP,
    ctx: OrganizationContext = ORG_ADMIN_DEP,
) -> OkResponse:
    """Delete a marketplace catalog entry and any install records that reference it."""
    skill = await _require_marketplace_skill_for_org(skill_id=skill_id, session=session, ctx=ctx)
    installations = await GatewayInstalledSkill.objects.filter_by(skill_id=skill.id).all(session)
    for installation in installations:
        await session.delete(installation)
    await session.delete(skill)
    await session.commit()
    return OkResponse()


@router.post(
    "/marketplace/{skill_id}/install",
    response_model=MarketplaceSkillActionResponse,
)
async def install_marketplace_skill(
    skill_id: UUID,
    gateway_id: UUID = GATEWAY_ID_QUERY,
    session: AsyncSession = SESSION_DEP,
    ctx: OrganizationContext = ORG_ADMIN_DEP,
) -> MarketplaceSkillActionResponse:
    """Install a marketplace skill by dispatching instructions to the gateway agent."""
    return await _run_marketplace_skill_action(
        session=session,
        ctx=ctx,
        skill_id=skill_id,
        gateway_id=gateway_id,
        installed=True,
    )


@router.post(
    "/marketplace/{skill_id}/uninstall",
    response_model=MarketplaceSkillActionResponse,
)
async def uninstall_marketplace_skill(
    skill_id: UUID,
    gateway_id: UUID = GATEWAY_ID_QUERY,
    session: AsyncSession = SESSION_DEP,
    ctx: OrganizationContext = ORG_ADMIN_DEP,
) -> MarketplaceSkillActionResponse:
    """Uninstall a marketplace skill by dispatching instructions to the gateway agent."""
    return await _run_marketplace_skill_action(
        session=session,
        ctx=ctx,
        skill_id=skill_id,
        gateway_id=gateway_id,
        installed=False,
    )


@router.get("/packs", response_model=list[SkillPackRead])
async def list_skill_packs(
    session: AsyncSession = SESSION_DEP,
    ctx: OrganizationContext = ORG_ADMIN_DEP,
) -> list[SkillPackRead]:
    """List skill packs configured for the organization."""
    packs = (
        await SkillPack.objects.filter_by(organization_id=ctx.organization.id)
        .order_by(col(SkillPack.created_at).desc())
        .all(session)
    )
    count_by_repo = await _load_pack_skill_count_by_repo(
        session=session,
        organization_id=ctx.organization.id,
    )
    return [
        _as_skill_pack_read_with_count(pack=pack, count_by_repo=count_by_repo) for pack in packs
    ]


@router.get("/packs/{pack_id}", response_model=SkillPackRead)
async def get_skill_pack(
    pack_id: UUID,
    session: AsyncSession = SESSION_DEP,
    ctx: OrganizationContext = ORG_ADMIN_DEP,
) -> SkillPackRead:
    """Get one skill pack by ID."""
    pack = await _require_skill_pack_for_org(pack_id=pack_id, session=session, ctx=ctx)
    count_by_repo = await _load_pack_skill_count_by_repo(
        session=session,
        organization_id=ctx.organization.id,
    )
    return _as_skill_pack_read_with_count(pack=pack, count_by_repo=count_by_repo)


@router.post("/packs", response_model=SkillPackRead)
async def create_skill_pack(
    payload: SkillPackCreate,
    session: AsyncSession = SESSION_DEP,
    ctx: OrganizationContext = ORG_ADMIN_DEP,
) -> SkillPackRead:
    """Register a new skill pack source URL."""
    source_url = _normalize_pack_source_url(str(payload.source_url))
    try:
        _validate_pack_source_url(source_url)
    except ValueError as exc:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(exc)) from exc

    existing = await SkillPack.objects.filter_by(
        organization_id=ctx.organization.id,
        source_url=source_url,
    ).first(session)
    if existing is not None:
        changed = False
        if payload.name and existing.name != payload.name:
            existing.name = payload.name
            changed = True
        if payload.description is not None and existing.description != payload.description:
            existing.description = payload.description
            changed = True
        normalized_branch = _normalize_pack_branch(payload.branch)
        if existing.branch != normalized_branch:
            existing.branch = normalized_branch
            changed = True
        if existing.metadata_ != payload.metadata_:
            existing.metadata_ = payload.metadata_
            changed = True
        if changed:
            existing.updated_at = utcnow()
            session.add(existing)
            await session.commit()
            await session.refresh(existing)
        count_by_repo = await _load_pack_skill_count_by_repo(
            session=session,
            organization_id=ctx.organization.id,
        )
        return _as_skill_pack_read_with_count(pack=existing, count_by_repo=count_by_repo)

    pack = SkillPack(
        organization_id=ctx.organization.id,
        source_url=source_url,
        name=payload.name or _infer_skill_name(source_url),
        description=payload.description,
        branch=_normalize_pack_branch(payload.branch),
        metadata_=payload.metadata_,
    )
    session.add(pack)
    await session.commit()
    await session.refresh(pack)
    count_by_repo = await _load_pack_skill_count_by_repo(
        session=session,
        organization_id=ctx.organization.id,
    )
    return _as_skill_pack_read_with_count(pack=pack, count_by_repo=count_by_repo)


@router.patch("/packs/{pack_id}", response_model=SkillPackRead)
async def update_skill_pack(
    pack_id: UUID,
    payload: SkillPackCreate,
    session: AsyncSession = SESSION_DEP,
    ctx: OrganizationContext = ORG_ADMIN_DEP,
) -> SkillPackRead:
    """Update a skill pack URL and metadata."""
    pack = await _require_skill_pack_for_org(pack_id=pack_id, session=session, ctx=ctx)
    source_url = _normalize_pack_source_url(str(payload.source_url))
    try:
        _validate_pack_source_url(source_url)
    except ValueError as exc:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(exc)) from exc

    duplicate = await SkillPack.objects.filter_by(
        organization_id=ctx.organization.id,
        source_url=source_url,
    ).first(session)
    if duplicate is not None and duplicate.id != pack.id:
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail="A pack with this source URL already exists",
        )

    pack.source_url = source_url
    pack.name = payload.name or _infer_skill_name(source_url)
    pack.description = payload.description
    pack.branch = _normalize_pack_branch(payload.branch)
    pack.metadata_ = payload.metadata_
    pack.updated_at = utcnow()
    session.add(pack)
    await session.commit()
    await session.refresh(pack)
    count_by_repo = await _load_pack_skill_count_by_repo(
        session=session,
        organization_id=ctx.organization.id,
    )
    return _as_skill_pack_read_with_count(pack=pack, count_by_repo=count_by_repo)


@router.delete("/packs/{pack_id}", response_model=OkResponse)
async def delete_skill_pack(
    pack_id: UUID,
    session: AsyncSession = SESSION_DEP,
    ctx: OrganizationContext = ORG_ADMIN_DEP,
) -> OkResponse:
    """Delete one pack source from the organization."""
    pack = await _require_skill_pack_for_org(pack_id=pack_id, session=session, ctx=ctx)
    await session.delete(pack)
    await session.commit()
    return OkResponse()


@router.post("/packs/{pack_id}/sync", response_model=SkillPackSyncResponse)
async def sync_skill_pack(
    pack_id: UUID,
    session: AsyncSession = SESSION_DEP,
    ctx: OrganizationContext = ORG_ADMIN_DEP,
) -> SkillPackSyncResponse:
    """Clone a pack repository and upsert discovered skills from `skills/**/SKILL.md`."""
    pack = await _require_skill_pack_for_org(pack_id=pack_id, session=session, ctx=ctx)

    try:
        _validate_pack_source_url(pack.source_url)
    except ValueError as exc:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(exc)) from exc

    try:
        discovered = _collect_pack_skills(
            source_url=pack.source_url,
        )
    except RuntimeError as exc:
        raise HTTPException(
            status_code=status.HTTP_502_BAD_GATEWAY,
            detail=str(exc),
        ) from exc

    existing_skills = await MarketplaceSkill.objects.filter_by(
        organization_id=ctx.organization.id,
    ).all(session)
    existing_by_source = {skill.source_url: skill for skill in existing_skills}

    created = 0
    updated = 0
    for candidate in discovered:
        existing = existing_by_source.get(candidate.source_url)
        if existing is None:
            session.add(
                MarketplaceSkill(
                    organization_id=ctx.organization.id,
                    source_url=candidate.source_url,
                    name=candidate.name,
                    description=candidate.description,
                    category=candidate.category,
                    risk=candidate.risk,
                    source=candidate.source,
                    metadata_=candidate.metadata or {},
                ),
            )
            created += 1
            continue

        changed = _apply_pack_candidate_updates(existing=existing, candidate=candidate)
        if changed:
            existing.updated_at = utcnow()
            session.add(existing)
            updated += 1

    await session.commit()

    return SkillPackSyncResponse(
        pack_id=pack.id,
        synced=len(discovered),
        created=created,
        updated=updated,
        warnings=[],
    )
